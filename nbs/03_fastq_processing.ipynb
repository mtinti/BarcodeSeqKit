{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTQ Processing\n",
    "\n",
    "> Processing FASTQ files for barcode extraction and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This notebook implements the FASTQ processing functionality for BarcodeSeqKit. It includes classes and functions for handling FASTQ files, extracting barcodes, and sorting reads into appropriate output files based on barcode detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp fastq_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import re\n",
    "import gzip\n",
    "import logging\n",
    "import shutil\n",
    "from typing import List, Dict, Tuple, Set, Optional, Union, Iterator, Any\n",
    "from pathlib import Path\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
    "import fnmatch\n",
    "from BarcodeSeqKit.core import (\n",
    "    BarcodeConfig, \n",
    "    BarcodeMatch, \n",
    "    OrientationType,\n",
    "    BarcodeExtractor, \n",
    "    ExtractionStatistics,\n",
    "    BarcodeLocationType\n",
    ")\n",
    "from BarcodeSeqKit.sequence_utils import classify_read_by_first_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTQ File Handler\n",
    "First, let's define a class to handle FASTQ file operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastqHandler:\n",
    "    \"\"\"Handles FASTQ file operations.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def find_fastq_pairs(directory: str) -> Tuple[str, str]:\n",
    "        \"\"\"Find paired FASTQ files in a directory.\n",
    "        \n",
    "        Args:\n",
    "            directory: Directory to search for FASTQ files\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (read1_path, read2_path)\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If paired FASTQ files cannot be found\n",
    "        \"\"\"\n",
    "        files = os.listdir(directory)\n",
    "        # Common naming patterns for paired FASTQ files\n",
    "        r1_patterns = ('_1.fq.gz', '_R1.fastq.gz', '_R1_001.fastq.gz')\n",
    "        r2_patterns = ('_2.fq.gz', '_R2.fastq.gz', '_R2_001.fastq.gz')\n",
    "        \n",
    "        # Find files matching the patterns\n",
    "        r1_file = None\n",
    "        r2_file = None\n",
    "        \n",
    "        for f in files:\n",
    "            if any(f.endswith(pattern) for pattern in r1_patterns):\n",
    "                r1_file = f\n",
    "            elif any(f.endswith(pattern) for pattern in r2_patterns):\n",
    "                r2_file = f\n",
    "        \n",
    "        if not (r1_file and r2_file):\n",
    "            raise ValueError(f\"Could not find paired FASTQ files in {directory}\")\n",
    "            \n",
    "        return os.path.join(directory, r1_file), os.path.join(directory, r2_file)\n",
    "    \n",
    "    @staticmethod\n",
    "    def open_fastq(filepath: str) -> Union[gzip.GzipFile, 'TextIOWrapper']:\n",
    "        \"\"\"Open a FASTQ file, handling gzipped and non-gzipped files.\n",
    "        \n",
    "        Args:\n",
    "            filepath: Path to the FASTQ file\n",
    "            \n",
    "        Returns:\n",
    "            An opened file handle\n",
    "        \"\"\"\n",
    "        if filepath.endswith(('.gz', '.gzip')):\n",
    "            return gzip.open(filepath, \"rt\")\n",
    "        else:\n",
    "            return open(filepath, \"rt\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def fastq_pair_iterator(r1_path: str, r2_path: str) -> Iterator[Tuple[Tuple, Tuple]]:\n",
    "        \"\"\"Create an iterator over paired FASTQ reads.\n",
    "        \n",
    "        Args:\n",
    "            r1_path: Path to the first read file\n",
    "            r2_path: Path to the second read file\n",
    "            \n",
    "        Returns:\n",
    "            Iterator yielding pairs of (read1, read2) tuples where each read is \n",
    "            a tuple of (title, sequence, quality)\n",
    "        \"\"\"\n",
    "        with FastqHandler.open_fastq(r1_path) as f1, FastqHandler.open_fastq(r2_path) as f2:\n",
    "            # Use the more efficient FastqGeneralIterator\n",
    "            for read1, read2 in zip(FastqGeneralIterator(f1), FastqGeneralIterator(f2)):\n",
    "                yield read1, read2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTQ Output Manager\n",
    "Now let's create a class to manage output FASTQ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastqOutputManager:\n",
    "    \"\"\"Manages output FASTQ files for different barcode categories.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        output_prefix: str,\n",
    "        output_dir: str,\n",
    "        categories: List[str],\n",
    "        compress: bool = True\n",
    "    ):\n",
    "        \"\"\"Initialize the output manager.\n",
    "        \n",
    "        Args:\n",
    "            output_prefix: Prefix for output files\n",
    "            output_dir: Directory for output files\n",
    "            categories: List of barcode categories (e.g., \"barcode5_orientFR\")\n",
    "            compress: Whether to compress output files\n",
    "        \"\"\"\n",
    "        self.output_prefix = output_prefix\n",
    "        self.output_dir = output_dir\n",
    "        self.categories = categories\n",
    "        self.compress = compress\n",
    "        self.file_handles = {}\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize file handles for each category\n",
    "        self._init_file_handles()\n",
    "    \n",
    "    def _init_file_handles(self):\n",
    "        \"\"\"Initialize file handles for all categories.\"\"\"\n",
    "        for category in self.categories:\n",
    "            self._open_category_files(category)\n",
    "    \n",
    "    def _open_category_files(self, category: str):\n",
    "        \"\"\"Open R1 and R2 files for a category.\n",
    "        \n",
    "        Args:\n",
    "            category: Barcode category\n",
    "        \"\"\"\n",
    "        r1_path = self._get_output_path(category, \"R1\")\n",
    "        r2_path = self._get_output_path(category, \"R2\")\n",
    "        \n",
    "        mode = \"wt\" if self.compress else \"w\"\n",
    "        \n",
    "        if self.compress:\n",
    "            self.file_handles[f\"{category}_R1\"] = gzip.open(r1_path, mode)\n",
    "            self.file_handles[f\"{category}_R2\"] = gzip.open(r2_path, mode)\n",
    "        else:\n",
    "            self.file_handles[f\"{category}_R1\"] = open(r1_path, mode)\n",
    "            self.file_handles[f\"{category}_R2\"] = open(r2_path, mode)\n",
    "    \n",
    "    def _get_output_path(self, category: str, read_suffix: str) -> str:\n",
    "        \"\"\"Generate an output file path based on category and read type.\n",
    "        \n",
    "        Args:\n",
    "            category: Barcode category\n",
    "            read_suffix: R1 or R2\n",
    "            \n",
    "        Returns:\n",
    "            Path to the output file\n",
    "        \"\"\"\n",
    "        if self.compress:\n",
    "            extension = \".fastq.gz\"\n",
    "        else:\n",
    "            extension = \".fastq\"\n",
    "            \n",
    "        filename = f\"{self.output_prefix}_{category}_{read_suffix}{extension}\"\n",
    "        return os.path.join(self.output_dir, filename)\n",
    "    \n",
    "    def write_read_pair(\n",
    "        self, \n",
    "        category: str, \n",
    "        read1: Tuple[str, str, str], \n",
    "        read2: Tuple[str, str, str]\n",
    "    ):\n",
    "        \"\"\"Write a read pair to the appropriate output files.\n",
    "        \n",
    "        Args:\n",
    "            category: Barcode category\n",
    "            read1: Read 1 tuple (title, sequence, quality)\n",
    "            read2: Read 2 tuple (title, sequence, quality)\n",
    "        \"\"\"\n",
    "        title1, seq1, qual1 = read1\n",
    "        title2, seq2, qual2 = read2\n",
    "        \n",
    "        r1_handle = self.file_handles[f\"{category}_R1\"]\n",
    "        r2_handle = self.file_handles[f\"{category}_R2\"]\n",
    "        \n",
    "        # Write in FastqGeneralIterator-compatible format\n",
    "        r1_handle.write(f\"@{title1}\\n{seq1}\\n+\\n{qual1}\\n\")\n",
    "        r2_handle.write(f\"@{title2}\\n{seq2}\\n+\\n{qual2}\\n\")\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close all file handles.\"\"\"\n",
    "        for handle in self.file_handles.values():\n",
    "            handle.close()\n",
    "        \n",
    "        self.file_handles = {}\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \"\"\"Context manager enter method.\"\"\"\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        \"\"\"Context manager exit method.\"\"\"\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FASTQ Extractor\n",
    "Now let's implement the main FASTQ extractor class that inherits from the BarcodeExtractor base class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastqExtractor(BarcodeExtractor):\n",
    "    \"\"\"Extracts barcodes from FASTQ files.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        barcodes: List[BarcodeConfig],\n",
    "        output_prefix: str,\n",
    "        fastq_files: List[str],\n",
    "        output_dir: Optional[str] = None,\n",
    "        merge_orientations: bool = False,\n",
    "        keep_unmatched: bool = True,\n",
    "        verbose: bool = False,\n",
    "        log_file: Optional[str] = None,\n",
    "        max_mismatches: int = 0,\n",
    "        compress_output: bool = True,\n",
    "        search_both_reads: bool = True\n",
    "    ):\n",
    "        \"\"\"Initialize the FASTQ extractor.\n",
    "        \n",
    "        Args:\n",
    "            barcodes: List of barcode configurations\n",
    "            output_prefix: Prefix for output files\n",
    "            fastq_files: List of FASTQ files (either 1 or 2 files)\n",
    "            output_dir: Directory for output files\n",
    "            merge_orientations: Whether to merge forward and reverse complement orientations\n",
    "            keep_unmatched: Whether to keep reads without barcodes\n",
    "            verbose: Whether to enable verbose logging\n",
    "            log_file: Path to log file\n",
    "            max_mismatches: Maximum number of mismatches allowed in barcode detection\n",
    "            compress_output: Whether to compress output files\n",
    "            search_both_reads: Whether to search for barcodes in both reads\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            barcodes=barcodes,\n",
    "            output_prefix=output_prefix,\n",
    "            output_dir=output_dir,\n",
    "            merge_orientations=merge_orientations,\n",
    "            keep_unmatched=keep_unmatched,\n",
    "            verbose=verbose,\n",
    "            log_file=log_file\n",
    "        )\n",
    "        \n",
    "        # Validate FASTQ files\n",
    "        if len(fastq_files) not in [1, 2]:\n",
    "            raise ValueError(\"Either 1 or 2 FASTQ files must be provided\")\n",
    "        \n",
    "        self.fastq_files = fastq_files\n",
    "        self.max_mismatches = max_mismatches\n",
    "        self.compress_output = compress_output\n",
    "        self.search_both_reads = search_both_reads\n",
    "        \n",
    "        # Determine if we have paired-end data\n",
    "        self.paired_end = len(fastq_files) == 2\n",
    "        \n",
    "        # Prepare output categories based on barcodes\n",
    "        self.categories = self._prepare_categories()\n",
    "        \n",
    "        self.logger.info(f\"Initialized FastqExtractor with {len(barcodes)} barcodes\")\n",
    "        self.logger.info(f\"FASTQ files: {fastq_files}\")\n",
    "        self.logger.info(f\"Output categories: {self.categories}\")\n",
    "    \n",
    "    def _prepare_categories(self) -> List[str]:\n",
    "        \"\"\"Prepare output categories based on barcodes.\n",
    "        \n",
    "        Returns:\n",
    "            List of category names\n",
    "        \"\"\"\n",
    "        categories = []\n",
    "        \n",
    "        # Single barcode mode (no location specified) or multiple barcodes\n",
    "        single_barcode_mode = all(b.location.value == \"UNK\" for b in self.barcodes)\n",
    "        \n",
    "        if single_barcode_mode:\n",
    "            if self.merge_orientations:\n",
    "                categories.append(\"barcode_orientAll\")\n",
    "            else:\n",
    "                categories.extend([\"barcode_orientFR\", \"barcode_orientRC\"])\n",
    "        else:\n",
    "            # Multiple barcodes with locations\n",
    "            for barcode in self.barcodes:\n",
    "                location = barcode.location.value\n",
    "                if location in [\"5\", \"3\"]:\n",
    "                    if self.merge_orientations:\n",
    "                        categories.append(f\"barcode{location}_orientAll\")\n",
    "                    else:\n",
    "                        categories.extend([\n",
    "                            f\"barcode{location}_orient{OrientationType.FORWARD.value}\",\n",
    "                            f\"barcode{location}_orient{OrientationType.REVERSE_COMPLEMENT.value}\"\n",
    "                        ])\n",
    "        \n",
    "        # Add combined categories\n",
    "        if len(self.barcodes) > 1 and not single_barcode_mode:\n",
    "            categories.append(\"combined_barcodeAll\")\n",
    "        \n",
    "        # Add no barcode category\n",
    "        if self.keep_unmatched:\n",
    "            categories.append(\"noBarcode\")\n",
    "        \n",
    "        return categories\n",
    "    \n",
    "    def extract(self) -> ExtractionStatistics:\n",
    "        \"\"\"Extract barcodes from FASTQ files.\n",
    "        \n",
    "        Returns:\n",
    "            Statistics from the extraction process\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Starting barcode extraction from FASTQ files\")\n",
    "        \n",
    "        # Initialize statistics\n",
    "        stats = ExtractionStatistics()\n",
    "        \n",
    "        # Initialize output files\n",
    "        with FastqOutputManager(\n",
    "            output_prefix=self.output_prefix,\n",
    "            output_dir=self.output_dir,\n",
    "            categories=self.categories,\n",
    "            compress=self.compress_output\n",
    "        ) as output_manager:\n",
    "            \n",
    "            # Process files\n",
    "            if self.paired_end:\n",
    "                self._process_paired_fastq(output_manager, stats)\n",
    "            else:\n",
    "                self._process_single_fastq(output_manager, stats)\n",
    "        \n",
    "        self.logger.info(f\"Extraction complete: {stats.total_barcode_matches} matches in {stats.total_reads} reads\")\n",
    "        \n",
    "        # Save statistics\n",
    "        self.save_statistics()\n",
    "        \n",
    "        # Create combined files if requested\n",
    "        if self.merge_orientations:\n",
    "            self._create_merged_files()\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def _process_paired_fastq(self, output_manager: FastqOutputManager, stats: ExtractionStatistics):\n",
    "        \"\"\"Process paired FASTQ files.\n",
    "        \n",
    "        Args:\n",
    "            output_manager: Output file manager\n",
    "            stats: Statistics object to update\n",
    "        \"\"\"\n",
    "        r1_path, r2_path = self.fastq_files\n",
    "        self.logger.info(f\"Processing paired FASTQ files: {r1_path}, {r2_path}\")\n",
    "        \n",
    "        read_count = 0\n",
    "        \n",
    "        for read1, read2 in FastqHandler.fastq_pair_iterator(r1_path, r2_path):\n",
    "            read_count += 1\n",
    "            stats.total_reads += 1\n",
    "            \n",
    "            # Update progress periodically\n",
    "            if read_count % 100000 == 0 and self.verbose:\n",
    "                self.logger.info(f\"Processed {read_count} read pairs\")\n",
    "            \n",
    "            # Extract title, sequence, and quality\n",
    "            title1, seq1, qual1 = read1\n",
    "            title2, seq2, qual2 = read2\n",
    "            \n",
    "            # Search for barcodes in read 1\n",
    "            match1, category1 = classify_read_by_first_match(\n",
    "                sequence=seq1,\n",
    "                barcodes=self.barcodes,\n",
    "                max_mismatches=self.max_mismatches\n",
    "            )\n",
    "            \n",
    "            # If barcode not found in read 1 and we're searching both reads\n",
    "            if category1 == \"noBarcode\" and self.search_both_reads:\n",
    "                match2, category2 = classify_read_by_first_match(\n",
    "                    sequence=seq2,\n",
    "                    barcodes=self.barcodes,\n",
    "                    max_mismatches=self.max_mismatches\n",
    "                )\n",
    "                \n",
    "                if category2 != \"noBarcode\":\n",
    "                    match = match2\n",
    "                    category = category2\n",
    "                else:\n",
    "                    match = None\n",
    "                    category = \"noBarcode\"\n",
    "            else:\n",
    "                match = match1\n",
    "                category = category1\n",
    "            \n",
    "            # Update statistics\n",
    "            if match:\n",
    "                stats.update_barcode_match(match)\n",
    "            else:\n",
    "                stats.no_barcode_count += 1\n",
    "            \n",
    "            # Handle orientation merging\n",
    "            if self.merge_orientations and match:\n",
    "                barcode_location = match.barcode.location.value\n",
    "                if barcode_location in [\"5\", \"3\"]:\n",
    "                    category = f\"barcode{barcode_location}_orientAll\"\n",
    "                else:\n",
    "                    category = \"barcode_orientAll\"\n",
    "            \n",
    "            # Write to appropriate output file\n",
    "            if match or self.keep_unmatched:\n",
    "                output_manager.write_read_pair(category, read1, read2)\n",
    "        \n",
    "        self.logger.info(f\"Finished processing {read_count} read pairs\")\n",
    "    \n",
    "    def _process_single_fastq(self, output_manager: FastqOutputManager, stats: ExtractionStatistics):\n",
    "        \"\"\"Process a single FASTQ file as if it were paired (for testing).\n",
    "        \n",
    "        Args:\n",
    "            output_manager: Output file manager\n",
    "            stats: Statistics object to update\n",
    "        \"\"\"\n",
    "        self.logger.warning(\"Processing single FASTQ file as paired (duplicating reads)\")\n",
    "        r1_path = self.fastq_files[0]\n",
    "        \n",
    "        read_count = 0\n",
    "        \n",
    "        with FastqHandler.open_fastq(r1_path) as f1:\n",
    "            for title, seq, qual in FastqGeneralIterator(f1):\n",
    "                read_count += 1\n",
    "                stats.total_reads += 1\n",
    "                \n",
    "                # Update progress periodically\n",
    "                if read_count % 100000 == 0 and self.verbose:\n",
    "                    self.logger.info(f\"Processed {read_count} reads\")\n",
    "                \n",
    "                # Package as a read tuple\n",
    "                read = (title, seq, qual)\n",
    "                \n",
    "                # Search for barcodes\n",
    "                match, category = classify_read_by_first_match(\n",
    "                    sequence=seq,\n",
    "                    barcodes=self.barcodes,\n",
    "                    max_mismatches=self.max_mismatches\n",
    "                )\n",
    "                \n",
    "                # Update statistics\n",
    "                if match:\n",
    "                    stats.update_barcode_match(match)\n",
    "                else:\n",
    "                    stats.no_barcode_count += 1\n",
    "                \n",
    "                # Handle orientation merging\n",
    "                if self.merge_orientations and match:\n",
    "                    barcode_location = match.barcode.location.value\n",
    "                    if barcode_location in [\"5\", \"3\"]:\n",
    "                        category = f\"barcode{barcode_location}_orientAll\"\n",
    "                    else:\n",
    "                        category = \"barcode_orientAll\"\n",
    "                \n",
    "                # Write to appropriate output file (duplicating the read for both R1 and R2)\n",
    "                if match or self.keep_unmatched:\n",
    "                    output_manager.write_read_pair(category, read, read)\n",
    "        \n",
    "        self.logger.info(f\"Finished processing {read_count} reads\")\n",
    "    \n",
    "    def _create_merged_files(self):\n",
    "        \"\"\"Create merged files for combined categories.\"\"\"\n",
    "        self.logger.info(\"Creating merged files for combined categories\")\n",
    "        \n",
    "        # Check if we need to create a combined file for all barcodes\n",
    "        single_barcode_mode = all(b.location.value == \"UNK\" for b in self.barcodes)\n",
    "        barcode_locations = set(b.location.value for b in self.barcodes if b.location.value in [\"5\", \"3\"])\n",
    "        \n",
    "        # Merge orientation files for each barcode location\n",
    "        for location in barcode_locations:\n",
    "            for read_suffix in [\"R1\", \"R2\"]:\n",
    "                out_file = os.path.join(\n",
    "                    self.output_dir, \n",
    "                    f\"{self.output_prefix}_combined_barcode{location}_{read_suffix}.fastq\"\n",
    "                )\n",
    "                \n",
    "                # Find all files for this barcode location\n",
    "                pattern = f\"{self.output_prefix}_barcode{location}_orient*_{read_suffix}.fastq\"\n",
    "                if self.compress_output:\n",
    "                    pattern += \".gz\"\n",
    "                    out_file += \".gz\"\n",
    "                \n",
    "                input_files = []\n",
    "                for f in os.listdir(self.output_dir):\n",
    "                    if fnmatch.fnmatch(f, pattern):\n",
    "                        input_files.append(os.path.join(self.output_dir, f))\n",
    "                \n",
    "                if input_files:\n",
    "                    self._merge_fastq_files(input_files, out_file)\n",
    "        \n",
    "        # Create a combined file for all barcodes if needed\n",
    "        if len(barcode_locations) > 1:\n",
    "            for read_suffix in [\"R1\", \"R2\"]:\n",
    "                out_file = os.path.join(\n",
    "                    self.output_dir, \n",
    "                    f\"{self.output_prefix}_combined_barcodeAll_{read_suffix}.fastq\"\n",
    "                )\n",
    "                \n",
    "                # Find all barcode files\n",
    "                pattern = f\"{self.output_prefix}_barcode*_orient*_{read_suffix}.fastq\"\n",
    "                if self.compress_output:\n",
    "                    pattern += \".gz\"\n",
    "                    out_file += \".gz\"\n",
    "                \n",
    "                input_files = []\n",
    "                for f in os.listdir(self.output_dir):\n",
    "                    if fnmatch.fnmatch(f, pattern):\n",
    "                        input_files.append(os.path.join(self.output_dir, f))\n",
    "                \n",
    "                if input_files:\n",
    "                    self._merge_fastq_files(input_files, out_file)\n",
    "    \n",
    "    def _merge_fastq_files(self, input_files: List[str], output_file: str):\n",
    "        \"\"\"Merge multiple FASTQ files into one.\n",
    "        \n",
    "        Args:\n",
    "            input_files: List of input file paths\n",
    "            output_file: Output file path\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Merging {len(input_files)} files into {output_file}\")\n",
    "        \n",
    "        if not input_files:\n",
    "            return\n",
    "        \n",
    "        # Check if files are compressed\n",
    "        is_compressed = input_files[0].endswith('.gz')\n",
    "        \n",
    "        if is_compressed:\n",
    "            with gzip.open(output_file, 'wb') as out_f:\n",
    "                for in_file in input_files:\n",
    "                    with gzip.open(in_file, 'rb') as in_f:\n",
    "                        shutil.copyfileobj(in_f, out_f)\n",
    "        else:\n",
    "            with open(output_file, 'wb') as out_f:\n",
    "                for in_file in input_files:\n",
    "                    with open(in_file, 'rb') as in_f:\n",
    "                        shutil.copyfileobj(in_f, out_f)\n",
    "    \n",
    "    def _find_barcode_matches(self, sequence: str) -> List[BarcodeMatch]:\n",
    "        \"\"\"Find barcode matches in a sequence.\n",
    "        \n",
    "        Note: This implementation uses classify_read_by_first_match instead of\n",
    "        finding all matches for efficiency.\n",
    "        \n",
    "        Args:\n",
    "            sequence: The sequence to search in\n",
    "            \n",
    "        Returns:\n",
    "            List of BarcodeMatch objects\n",
    "        \"\"\"\n",
    "        match, _ = classify_read_by_first_match(\n",
    "            sequence=sequence,\n",
    "            barcodes=self.barcodes,\n",
    "            max_mismatches=self.max_mismatches\n",
    "        )\n",
    "        \n",
    "        if match:\n",
    "            return [match]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage\n",
    "Let's demonstrate how to use the FASTQ extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 18:03:30,169 - BarcodeSeqKit - INFO - Initialized FastqExtractor with 2 barcodes\n",
      "2025-03-12 18:03:30,169 - BarcodeSeqKit - INFO - Initialized FastqExtractor with 2 barcodes\n",
      "2025-03-12 18:03:30,169 - BarcodeSeqKit - INFO - FASTQ files: ['/var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R1.fastq.gz', '/var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R2.fastq.gz']\n",
      "2025-03-12 18:03:30,169 - BarcodeSeqKit - INFO - FASTQ files: ['/var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R1.fastq.gz', '/var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R2.fastq.gz']\n",
      "2025-03-12 18:03:30,170 - BarcodeSeqKit - INFO - Output categories: ['barcode5_orientFR', 'barcode5_orientRC', 'barcode3_orientFR', 'barcode3_orientRC', 'combined_barcodeAll', 'noBarcode']\n",
      "2025-03-12 18:03:30,170 - BarcodeSeqKit - INFO - Output categories: ['barcode5_orientFR', 'barcode5_orientRC', 'barcode3_orientFR', 'barcode3_orientRC', 'combined_barcodeAll', 'noBarcode']\n",
      "2025-03-12 18:03:30,171 - BarcodeSeqKit - INFO - Starting barcode extraction from FASTQ files\n",
      "2025-03-12 18:03:30,171 - BarcodeSeqKit - INFO - Starting barcode extraction from FASTQ files\n",
      "2025-03-12 18:03:30,181 - BarcodeSeqKit - INFO - Processing paired FASTQ files: /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R1.fastq.gz, /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R2.fastq.gz\n",
      "2025-03-12 18:03:30,181 - BarcodeSeqKit - INFO - Processing paired FASTQ files: /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R1.fastq.gz, /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/test_R2.fastq.gz\n",
      "2025-03-12 18:03:30,241 - BarcodeSeqKit - INFO - Finished processing 3 read pairs\n",
      "2025-03-12 18:03:30,241 - BarcodeSeqKit - INFO - Finished processing 3 read pairs\n",
      "2025-03-12 18:03:30,245 - BarcodeSeqKit - INFO - Extraction complete: 2 matches in 3 reads\n",
      "2025-03-12 18:03:30,245 - BarcodeSeqKit - INFO - Extraction complete: 2 matches in 3 reads\n",
      "2025-03-12 18:03:30,252 - BarcodeSeqKit - INFO - Statistics saved to /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/output/test_extraction_stats.json and /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/output/test_extraction_stats.tsv\n",
      "2025-03-12 18:03:30,252 - BarcodeSeqKit - INFO - Statistics saved to /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/output/test_extraction_stats.json and /var/folders/r1/gf3p5gjs5j9gw_49cj98r8b00000gp/T/tmp8vltvt_v/output/test_extraction_stats.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reads: 3\n",
      "Barcode matches: 2\n",
      "No barcode: 1\n",
      "Matches by barcode: {'5': 1, '3': 1}\n",
      "Matches by orientation: {'FR': 2}\n",
      "\n",
      "Output files:\n",
      "- test_barcode3_orientRC_R2.fastq.gz\n",
      "- test_barcode3_orientFR_R1.fastq.gz\n",
      "- test_extraction_stats.json\n",
      "- test_combined_barcodeAll_R2.fastq.gz\n",
      "- test_extraction_stats.tsv\n",
      "- test_noBarcode_R2.fastq.gz\n",
      "- test_barcode5_orientRC_R1.fastq.gz\n",
      "- test_barcode5_orientFR_R2.fastq.gz\n",
      "- test_combined_barcodeAll_R1.fastq.gz\n",
      "- test_barcode3_orientFR_R2.fastq.gz\n",
      "- test_barcode3_orientRC_R1.fastq.gz\n",
      "- test_barcode5_orientFR_R1.fastq.gz\n",
      "- test_noBarcode_R1.fastq.gz\n",
      "- test_barcode5_orientRC_R2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the FastqExtractor\n",
    "\n",
    "# Create barcode configurations\n",
    "barcode_5prime = BarcodeConfig(\n",
    "    sequence=\"ACGTACGT\",\n",
    "    location=BarcodeLocationType.FIVE_PRIME,\n",
    "    name=\"5\",\n",
    "    description=\"5' barcode example\"\n",
    ")\n",
    "\n",
    "barcode_3prime = BarcodeConfig(\n",
    "    sequence=\"TGCATGCA\",\n",
    "    location=BarcodeLocationType.THREE_PRIME,\n",
    "    name=\"3\",\n",
    "    description=\"3' barcode example\"\n",
    ")\n",
    "\n",
    "# Create a test FASTQ file\n",
    "import gzip\n",
    "import tempfile\n",
    "\n",
    "def create_test_fastq_files():\n",
    "    \"\"\"Create test FASTQ files for demonstration.\"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # Create R1 file with some barcoded reads\n",
    "    r1_path = os.path.join(temp_dir, \"test_R1.fastq.gz\")\n",
    "    with gzip.open(r1_path, 'wt') as f:\n",
    "        # Read with 5' barcode\n",
    "        f.write(\"@read1\\n\")\n",
    "        f.write(\"ACGTACGTAAAAAAAAAAAAAAAA\\n\")\n",
    "        f.write(\"+\\n\")\n",
    "        f.write(\"ACGTACGTAAAAAAAAAAAAAAAA\\n\")\n",
    "        \n",
    "        # Read with 3' barcode\n",
    "        f.write(\"@read2\\n\")\n",
    "        f.write(\"AAAAAAAAAAAAAAAATGCATGCA\\n\")\n",
    "        f.write(\"+\\n\")\n",
    "        f.write(\"AAAAAAAAAAAAAAAATGCATGCA\\n\")\n",
    "        \n",
    "        # Read with no barcode\n",
    "        f.write(\"@read3\\n\")\n",
    "        f.write(\"AAAAAAAAAAAAAAAAAAAAAAAA\\n\")\n",
    "        f.write(\"+\\n\")\n",
    "        f.write(\"AAAAAAAAAAAAAAAAAAAAAAAA\\n\")\n",
    "    \n",
    "    # Create R2 file with some barcoded reads\n",
    "    r2_path = os.path.join(temp_dir, \"test_R2.fastq.gz\")\n",
    "    with gzip.open(r2_path, 'wt') as f:\n",
    "        # Matching reads for R1\n",
    "        f.write(\"@read1\\n\")\n",
    "        f.write(\"TTTTTTTTTTTTTTTTTTTTTTTT\\n\")\n",
    "        f.write(\"+\\n\")\n",
    "        f.write(\"TTTTTTTTTTTTTTTTTTTTTTTT\\n\")\n",
    "        \n",
    "        f.write(\"@read2\\n\")\n",
    "        f.write(\"TTTTTTTTTTTTTTTTTTTTTTTT\\n\")\n",
    "        f.write(\"+\\n\")\n",
    "        f.write(\"TTTTTTTTTTTTTTTTTTTTTTTT\\n\")\n",
    "        \n",
    "        f.write(\"@read3\\n\")\n",
    "        f.write(\"TTTTTTTTTTTTTTTTTTTTTTTT\\n\")\n",
    "        f.write(\"+\\n\")\n",
    "        f.write(\"TTTTTTTTTTTTTTTTTTTTTTTT\\n\")\n",
    "    \n",
    "    return r1_path, r2_path, temp_dir\n",
    "\n",
    "# Create the test files\n",
    "r1_path, r2_path, temp_dir = create_test_fastq_files()\n",
    "\n",
    "# Create an output directory\n",
    "output_dir = os.path.join(temp_dir, \"output\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the extractor\n",
    "extractor = FastqExtractor(\n",
    "    barcodes=[barcode_5prime, barcode_3prime],\n",
    "    output_prefix=\"test\",\n",
    "    fastq_files=[r1_path, r2_path],\n",
    "    output_dir=output_dir,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the extraction\n",
    "stats = extractor.extract()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total reads: {stats.total_reads}\")\n",
    "print(f\"Barcode matches: {stats.total_barcode_matches}\")\n",
    "print(f\"No barcode: {stats.no_barcode_count}\")\n",
    "print(f\"Matches by barcode: {stats.matches_by_barcode}\")\n",
    "print(f\"Matches by orientation: {stats.matches_by_orientation}\")\n",
    "\n",
    "# List the output files\n",
    "print(\"\\nOutput files:\")\n",
    "for f in os.listdir(output_dir):\n",
    "    print(f\"- {f}\")\n",
    "\n",
    "# Clean up temporary files\n",
    "import shutil\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This notebook implements the FASTQ processing functionality for BarcodeSeqKit, providing efficient extraction and classification of barcoded reads from FASTQ files. The implementation uses the efficient FastqGeneralIterator for parsing FASTQ files and provides flexibility for handling both single-end and paired-end data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
